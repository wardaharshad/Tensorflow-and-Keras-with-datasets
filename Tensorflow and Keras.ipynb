{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "breathing-necklace",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "administrative-tablet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 2  8 18 32 50], shape=(5,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "x1 = tf.constant([1,2,3,4,5])\n",
    "x2 = tf.constant([2,4,6,8,10])\n",
    "\n",
    "#Multiply\n",
    "result = tf.multiply(x1,x2)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "apparent-campaign",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 3  6  9 12 15], shape=(5,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "x1 = tf.constant([1,2,3,4,5])\n",
    "x2 = tf.constant([2,4,6,8,10])\n",
    "\n",
    "#Multiply\n",
    "result = tf.add(x1,x2)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "portable-shaft",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([-1 -2 -3 -4 -5], shape=(5,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "x1 = tf.constant([1,2,3,4,5])\n",
    "x2 = tf.constant([2,4,6,8,10])\n",
    "\n",
    "#Multiply\n",
    "result = tf.subtract(x1,x2)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changed-audio",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#make numpy values easier to read.\n",
    "np.set_printoptions(precision = 3, suppress = True)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import preprocessing\n",
    "\n",
    "abc_train=pd.read_csv('https://storage.googleapis.com/download.tensorflow.org/data/abalone_train.csv',\n",
    "                       names = [\"Length\", \"Diameter\", \"Height\", \"Whole weight\", \n",
    "                                \"shucked weight\", \"Viscera weight\", \"Shell weight\", \"Age\"])\n",
    "\n",
    "abc_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "drawn-creativity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-datasets\n",
      "  Downloading tensorflow_datasets-4.2.0-py3-none-any.whl (3.7 MB)\n",
      "Collecting importlib-resources\n",
      "  Downloading importlib_resources-5.1.2-py3-none-any.whl (25 kB)\n",
      "Collecting future\n",
      "  Downloading future-0.18.2.tar.gz (829 kB)\n",
      "Collecting promise\n",
      "  Downloading promise-2.3.tar.gz (19 kB)\n",
      "Collecting tensorflow-metadata\n",
      "  Downloading tensorflow_metadata-0.29.0-py3-none-any.whl (47 kB)\n",
      "Requirement already satisfied: absl-py in c:\\users\\tls\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-datasets) (0.11.0)\n",
      "Collecting dill\n",
      "  Downloading dill-0.3.3-py2.py3-none-any.whl (81 kB)\n",
      "Requirement already satisfied: termcolor in c:\\users\\tls\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-datasets) (1.1.0)\n",
      "Requirement already satisfied: attrs>=18.1.0 in c:\\users\\tls\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-datasets) (20.3.0)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.60.0-py2.py3-none-any.whl (75 kB)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\tls\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-datasets) (2.25.1)\n",
      "Requirement already satisfied: six in c:\\users\\tls\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-datasets) (1.15.0)\n",
      "Requirement already satisfied: protobuf>=3.12.2 in c:\\users\\tls\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-datasets) (3.14.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\tls\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-datasets) (1.19.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\tls\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests>=2.19.0->tensorflow-datasets) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\tls\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests>=2.19.0->tensorflow-datasets) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\tls\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests>=2.19.0->tensorflow-datasets) (1.26.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\tls\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests>=2.19.0->tensorflow-datasets) (2020.12.5)\n",
      "Collecting googleapis-common-protos<2,>=1.52.0\n",
      "  Downloading googleapis_common_protos-1.53.0-py2.py3-none-any.whl (198 kB)\n",
      "Building wheels for collected packages: future, promise\n",
      "  Building wheel for future (setup.py): started\n",
      "  Building wheel for future (setup.py): finished with status 'done'\n",
      "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491059 sha256=f42d5178cf535922d518da3a440e6b0c2fb502b7c4a89277dd5af8203be98b6f\n",
      "  Stored in directory: c:\\users\\tls\\appdata\\local\\pip\\cache\\wheels\\8e\\70\\28\\3d6ccd6e315f65f245da085482a2e1c7d14b90b30f239e2cf4\n",
      "  Building wheel for promise (setup.py): started\n",
      "  Building wheel for promise (setup.py): finished with status 'done'\n",
      "  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21494 sha256=c9527dc5641af4d514ae62e6df6f34ce7ffbc713866d440afb185e0461284b74\n",
      "  Stored in directory: c:\\users\\tls\\appdata\\local\\pip\\cache\\wheels\\54\\aa\\01\\724885182f93150035a2a91bce34a12877e8067a97baaf5dc8\n",
      "Successfully built future promise\n",
      "Installing collected packages: googleapis-common-protos, tqdm, tensorflow-metadata, promise, importlib-resources, future, dill, tensorflow-datasets\n",
      "Successfully installed dill-0.3.3 future-0.18.2 googleapis-common-protos-1.53.0 importlib-resources-5.1.2 promise-2.3 tensorflow-datasets-4.2.0 tensorflow-metadata-0.29.0 tqdm-4.60.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bronze-landing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "sunset-slovak",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abstract_reasoning',\n",
       " 'accentdb',\n",
       " 'aeslc',\n",
       " 'aflw2k3d',\n",
       " 'ag_news_subset',\n",
       " 'ai2_arc',\n",
       " 'ai2_arc_with_ir',\n",
       " 'amazon_us_reviews',\n",
       " 'anli',\n",
       " 'arc',\n",
       " 'bair_robot_pushing_small',\n",
       " 'bccd',\n",
       " 'beans',\n",
       " 'big_patent',\n",
       " 'bigearthnet',\n",
       " 'billsum',\n",
       " 'binarized_mnist',\n",
       " 'binary_alpha_digits',\n",
       " 'blimp',\n",
       " 'bool_q',\n",
       " 'c4',\n",
       " 'caltech101',\n",
       " 'caltech_birds2010',\n",
       " 'caltech_birds2011',\n",
       " 'cars196',\n",
       " 'cassava',\n",
       " 'cats_vs_dogs',\n",
       " 'celeb_a',\n",
       " 'celeb_a_hq',\n",
       " 'cfq',\n",
       " 'cherry_blossoms',\n",
       " 'chexpert',\n",
       " 'cifar10',\n",
       " 'cifar100',\n",
       " 'cifar10_1',\n",
       " 'cifar10_corrupted',\n",
       " 'citrus_leaves',\n",
       " 'cityscapes',\n",
       " 'civil_comments',\n",
       " 'clevr',\n",
       " 'clic',\n",
       " 'clinc_oos',\n",
       " 'cmaterdb',\n",
       " 'cnn_dailymail',\n",
       " 'coco',\n",
       " 'coco_captions',\n",
       " 'coil100',\n",
       " 'colorectal_histology',\n",
       " 'colorectal_histology_large',\n",
       " 'common_voice',\n",
       " 'coqa',\n",
       " 'cos_e',\n",
       " 'cosmos_qa',\n",
       " 'covid19sum',\n",
       " 'crema_d',\n",
       " 'curated_breast_imaging_ddsm',\n",
       " 'cycle_gan',\n",
       " 'dart',\n",
       " 'davis',\n",
       " 'deep_weeds',\n",
       " 'definite_pronoun_resolution',\n",
       " 'dementiabank',\n",
       " 'diabetic_retinopathy_detection',\n",
       " 'div2k',\n",
       " 'dmlab',\n",
       " 'downsampled_imagenet',\n",
       " 'drop',\n",
       " 'dsprites',\n",
       " 'dtd',\n",
       " 'duke_ultrasound',\n",
       " 'e2e_cleaned',\n",
       " 'emnist',\n",
       " 'eraser_multi_rc',\n",
       " 'esnli',\n",
       " 'eurosat',\n",
       " 'fashion_mnist',\n",
       " 'flic',\n",
       " 'flores',\n",
       " 'food101',\n",
       " 'forest_fires',\n",
       " 'fuss',\n",
       " 'gap',\n",
       " 'geirhos_conflict_stimuli',\n",
       " 'genomics_ood',\n",
       " 'german_credit_numeric',\n",
       " 'gigaword',\n",
       " 'glue',\n",
       " 'goemotions',\n",
       " 'gpt3',\n",
       " 'groove',\n",
       " 'gtzan',\n",
       " 'gtzan_music_speech',\n",
       " 'hellaswag',\n",
       " 'higgs',\n",
       " 'horses_or_humans',\n",
       " 'howell',\n",
       " 'i_naturalist2017',\n",
       " 'imagenet2012',\n",
       " 'imagenet2012_corrupted',\n",
       " 'imagenet2012_real',\n",
       " 'imagenet2012_subset',\n",
       " 'imagenet_a',\n",
       " 'imagenet_r',\n",
       " 'imagenet_resized',\n",
       " 'imagenet_v2',\n",
       " 'imagenette',\n",
       " 'imagewang',\n",
       " 'imdb_reviews',\n",
       " 'irc_disentanglement',\n",
       " 'iris',\n",
       " 'kitti',\n",
       " 'kmnist',\n",
       " 'lambada',\n",
       " 'lfw',\n",
       " 'librispeech',\n",
       " 'librispeech_lm',\n",
       " 'libritts',\n",
       " 'ljspeech',\n",
       " 'lm1b',\n",
       " 'lost_and_found',\n",
       " 'lsun',\n",
       " 'lvis',\n",
       " 'malaria',\n",
       " 'math_dataset',\n",
       " 'mctaco',\n",
       " 'mlqa',\n",
       " 'mnist',\n",
       " 'mnist_corrupted',\n",
       " 'movie_lens',\n",
       " 'movie_rationales',\n",
       " 'movielens',\n",
       " 'moving_mnist',\n",
       " 'multi_news',\n",
       " 'multi_nli',\n",
       " 'multi_nli_mismatch',\n",
       " 'natural_questions',\n",
       " 'natural_questions_open',\n",
       " 'newsroom',\n",
       " 'nsynth',\n",
       " 'nyu_depth_v2',\n",
       " 'omniglot',\n",
       " 'open_images_challenge2019_detection',\n",
       " 'open_images_v4',\n",
       " 'openbookqa',\n",
       " 'opinion_abstracts',\n",
       " 'opinosis',\n",
       " 'opus',\n",
       " 'oxford_flowers102',\n",
       " 'oxford_iiit_pet',\n",
       " 'para_crawl',\n",
       " 'patch_camelyon',\n",
       " 'paws_wiki',\n",
       " 'paws_x_wiki',\n",
       " 'pet_finder',\n",
       " 'pg19',\n",
       " 'piqa',\n",
       " 'places365_small',\n",
       " 'plant_leaves',\n",
       " 'plant_village',\n",
       " 'plantae_k',\n",
       " 'qa4mre',\n",
       " 'qasc',\n",
       " 'quac',\n",
       " 'quickdraw_bitmap',\n",
       " 'race',\n",
       " 'radon',\n",
       " 'reddit',\n",
       " 'reddit_disentanglement',\n",
       " 'reddit_tifu',\n",
       " 'resisc45',\n",
       " 'robonet',\n",
       " 'rock_paper_scissors',\n",
       " 'rock_you',\n",
       " 's3o4d',\n",
       " 'salient_span_wikipedia',\n",
       " 'samsum',\n",
       " 'savee',\n",
       " 'scan',\n",
       " 'scene_parse150',\n",
       " 'scicite',\n",
       " 'scientific_papers',\n",
       " 'sentiment140',\n",
       " 'shapes3d',\n",
       " 'siscore',\n",
       " 'smallnorb',\n",
       " 'snli',\n",
       " 'so2sat',\n",
       " 'speech_commands',\n",
       " 'spoken_digit',\n",
       " 'squad',\n",
       " 'stanford_dogs',\n",
       " 'stanford_online_products',\n",
       " 'starcraft_video',\n",
       " 'stl10',\n",
       " 'story_cloze',\n",
       " 'sun397',\n",
       " 'super_glue',\n",
       " 'svhn_cropped',\n",
       " 'ted_hrlr_translate',\n",
       " 'ted_multi_translate',\n",
       " 'tedlium',\n",
       " 'tf_flowers',\n",
       " 'the300w_lp',\n",
       " 'tiny_shakespeare',\n",
       " 'titanic',\n",
       " 'trec',\n",
       " 'trivia_qa',\n",
       " 'tydi_qa',\n",
       " 'uc_merced',\n",
       " 'ucf101',\n",
       " 'vctk',\n",
       " 'vgg_face2',\n",
       " 'visual_domain_decathlon',\n",
       " 'voc',\n",
       " 'voxceleb',\n",
       " 'voxforge',\n",
       " 'waymo_open_dataset',\n",
       " 'web_nlg',\n",
       " 'web_questions',\n",
       " 'wider_face',\n",
       " 'wiki40b',\n",
       " 'wiki_bio',\n",
       " 'wiki_table_questions',\n",
       " 'wiki_table_text',\n",
       " 'wikihow',\n",
       " 'wikipedia',\n",
       " 'wikipedia_toxicity_subtypes',\n",
       " 'wine_quality',\n",
       " 'winogrande',\n",
       " 'wmt14_translate',\n",
       " 'wmt15_translate',\n",
       " 'wmt16_translate',\n",
       " 'wmt17_translate',\n",
       " 'wmt18_translate',\n",
       " 'wmt19_translate',\n",
       " 'wmt_t2t_translate',\n",
       " 'wmt_translate',\n",
       " 'wordnet',\n",
       " 'wsc273',\n",
       " 'xnli',\n",
       " 'xquad',\n",
       " 'xsum',\n",
       " 'xtreme_pawsx',\n",
       " 'xtreme_xnli',\n",
       " 'yelp_polarity_reviews',\n",
       " 'yes_no']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#available datasets\n",
    "tfds.list_builders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "random-principal",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
